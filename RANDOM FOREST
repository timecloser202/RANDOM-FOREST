# Load libraries
library(caret)
library(dplyr)
library(lubridate)
library(readr)
library(randomForest)
library(ggplot2) 

# Define file paths with corresponding tickers
files <- c(
  "/kaggle/input/final-merged-dataset/AAPL_merged_data (1).csv" = "AAPL",
  "/kaggle/input/final-merged-dataset/AMZN_merged_data (1).csv" = "AMZN",
  "/kaggle/input/final-merged-dataset/GOOG_merged_data (1).csv" = "GOOG",
  "/kaggle/input/final-merged-dataset/MSFT_merged_data (1).csv" = "MSFT",
  "/kaggle/input/final-merged-dataset/TSLA_merged_data (1).csv" = "TSLA"
)
# Read the files and add the Ticker column
data_list <- lapply(names(files), function(file) {
  data <- read_csv(file)
  data$Ticker <- files[[file]]  # Add Ticker column
  return(data)
})

# Merge and prepare the dataset
full_dataset <- bind_rows(data_list) %>%
  mutate(Date = ymd(Date)) %>%
  arrange(Date) %>%
  group_by(Ticker) %>%
  mutate(
    Excess_Return = diff(c(NA, Excess_Return)), # First derivative to deseasonalize
    across(c("RSI", "Volatility"), 
           .fns = list(
             lag1 = ~lag(.x, 1),
             lag2 = ~lag(.x, 2),
             lag3 = ~lag(.x, 3)
           )
    ),
    Excess_Return_lag1 = lag(Excess_Return, 1),
    Excess_Return_lag2 = lag(Excess_Return, 2),
    Excess_Return_lag3 = lag(Excess_Return, 3),
    Year = year(Date),
    Quarter = quarter(Date),
    Month = month(Date),
    Week = week(Date),
    DayOfWeek = wday(Date),
    DayOfYear = yday(Date)
  ) %>%
  ungroup()

# Function to create Fourier terms
create_fourier_terms <- function(data, K, period) {
  for (k in 1:K) {
    data[[paste0("sin_", k)]] <- sin(2 * pi * k * data$DayOfYear / period)
    data[[paste0("cos_", k)]] <- cos(2 * pi * k * data$DayOfYear / period)
  }
  return(data)
}

# Adding Fourier terms for annual seasonality (252 days period)
full_dataset <- create_fourier_terms(full_dataset, K = 5, period = 252)

# Time-based split for training and testing sets
split_date <- as.Date("2019-01-01") # Example split date, adjust as needed
train_data <- filter(full_dataset, Date < split_date)
test_data <- filter(full_dataset, Date >= split_date)

# Subsetting train_data and test_data
train_data <- train_data[21:nrow(train_data),]
test_data <- test_data[21:nrow(test_data),]

# Feature selection
features <- c("RSI", "Volatility","Avg_Volume", "Excess_Return_lag1", "Excess_Return_lag2",
              "Excess_Return_lag3","sin_1", "cos_1", "sin_2", "cos_2", "sin_3", "cos_3")
# Apply transformations
train_data$"Rolling Sentiment" <- scale(train_data$"Rolling Sentiment")
test_data$"Rolling Sentiment" <- scale(test_data$"Rolling Sentiment")

# Create interaction terms
train_data$"Rolling_Sentiment_Avg_Volume" <- train_data$"Rolling Sentiment" * train_data$"Avg_Volume"
test_data$"Rolling_Sentiment_Avg_Volume" <- test_data$"Rolling Sentiment" * test_data$"Avg_Volume"

# Update features
features <- c(features, "Rolling_Sentiment_Avg_Volume")


train_features <- train_data[, features]
test_features <- test_data[, features]


# Median imputation for missing values in train_labels
train_labels <- train_data$Excess_Return
if (any(is.na(train_labels)) || any(is.nan(train_labels))) {
  train_labels[is.na(train_labels) | is.nan(train_labels)] <- median(train_labels, na.rm = TRUE)
}

# Cross-validation
set.seed(123)  # for reproducibility
model_rf_cv <- train(x = train_features, y = train_labels, method = "rf", 
                     trControl = trainControl(method = "cv", number = 5), 
                     tuneGrid = expand.grid(mtry = c(2, 4, 6, 8)))

# Get the best model
best_model <- model_rf_cv$finalModel

# Predictions on the test set
predictions_rf <- predict(best_model, newdata = test_features)

# Plotting Actual vs Predicted Excess Returns over Time
test_data$Predicted_Return <- predictions_rf
ggplot(test_data, aes(x = Date)) +
  geom_line(aes(y = Excess_Return, colour = "Actual")) +
  geom_line(aes(y = Predicted_Return, colour = "Predicted")) +
  labs(title = "Actual vs Predicted Excess Returns Over Time",
       x = "Date", y = "Excess Return") +
  theme_minimal() +
  scale_colour_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Evaluation metrics
rss <- sum((test_data$Excess_Return - test_data$Predicted_Return)^2)
tss <- sum((test_data$Excess_Return)^2)
R2 <- 1 - rss / tss

n <- nrow(test_data)
p <- length(features)  # Number of predictors/features used in the model
R2_adj <- 1 - (1 - R2) * (n - 1) / (n - p - 1)

# Print evaluation metrics
cat("Out-of-Sample R-squared:", R2, "\n")
cat("Adjusted R-squared:", R2_adj, "\n")
cat("Correlation:", cor(test_data$Predicted_Return, test_data$Excess_Return, use = "complete.obs"), "\n")
cat("RMSE:", sqrt(mean((test_data$Predicted_Return - test_data$Excess_Return)^2, na.rm = TRUE)), "\n")
cat("MSE:", mean((test_data$Predicted_Return - test_data$Excess_Return)^2, na.rm = TRUE), "\n")

# Feature importance
importance <- varImp(best_model)
print(importance)
